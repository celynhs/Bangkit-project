{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/celynhs/Bangkit-project/blob/main/Deployment_for_CC_BeBi_(Beli_Bijak).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGFjjYoFrU0q"
      },
      "source": [
        "# Upload Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "connect gdrive to colab (not used in .py file)\n"
      ],
      "metadata": {
        "id": "DkPMxROnyl42"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dOvnVG54i_n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f1d3585-6afe-4cad-d561-893caf8ba4dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mifpNcbDreEj"
      },
      "source": [
        "import modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IijeeW5q5-gb"
      },
      "outputs": [],
      "source": [
        "# import modules\n",
        "import math\n",
        "import scipy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiOQVUlT6zAL"
      },
      "source": [
        "# Model Deployment "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## deploy model"
      ],
      "metadata": {
        "id": "oH1Gp1nPROfb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "functions to combine the 2 models and process the results "
      ],
      "metadata": {
        "id": "uz7yQ1Kkyu7c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvN0mqjr_NiT"
      },
      "outputs": [],
      "source": [
        "# get recommendation from collaborative filtering\n",
        "def collaborative_filtering_model(df,dataset, user_id,clfmodel):\n",
        "  # Generate item recommendations for a specific user\n",
        "  num_products = len(dataset['product_id'].unique())\n",
        "  user_mapping = {user_id: i for i, user_id in enumerate(dataset['user_id'].unique())}\n",
        "  product_mapping = {item_id: i for i, item_id in enumerate(dataset['product_id'].unique())}\n",
        "  user_products = np.full((num_products,), user_mapping[user_id])\n",
        "  products_ids = np.arange(num_products)\n",
        "\n",
        "  # Predict ratings for the user-item combinations\n",
        "  predictions = clfmodel.predict([user_products, products_ids]).flatten()\n",
        "\n",
        "  # Create pandas DataFrame of predictions for the user\n",
        "  recs_df = pd.DataFrame({'product_id': product_mapping.keys(), 'rating': predictions})\n",
        "\n",
        "  # Sort DataFrame by the predicted rating in descending order\n",
        "  recs_df = recs_df.sort_values('rating', ascending=False)\n",
        "\n",
        "  # Select the top 10 recommendations\n",
        "  top_10_recs = recs_df.nlargest(n, 'rating') # select top 10 recs\n",
        "  clfrecs = top_10_recs[['product_id', 'rating']] # choose specific column from the dataframe\n",
        "  clfrecs = clfrecs.rename(columns={'rating': 'clf_ratings'}) # rename rating column to clf_ratings\n",
        "  clfinfo = pd.merge(clfrecs,df,on='product_id') # merge the data with df to get info about the product id\n",
        "  clfinfo = clfinfo.drop_duplicates(subset='product_id', keep='first') # drop all the duplicates (1 row for 1 product id without user info)\n",
        "  clfinfo = clfinfo.drop(['user_id','add_to_cart_order','reordered','actual_price','ratings','brand'],axis=1) # drop unnecessary columns\n",
        "  # reordered the column\n",
        "  column_index = clfinfo.columns.get_loc('clf_ratings') \n",
        "  new_columns = list(clfinfo.columns[:column_index]) + list(clfinfo.columns[column_index+1:]) + ['clf_ratings']\n",
        "  clfinfo = clfinfo[new_columns]\n",
        "\n",
        "  return clfinfo\n",
        "\n",
        "# get recommendations from content based ratings\n",
        "def content_based_model(df, dataset, user_id, cbfmodel):\n",
        "  # Predict the ratings for all products in the dataset\n",
        "  all_products = dataset[dataset['user_id'] != user_id]\n",
        "  X_all = [all_products['category_id'], all_products[[\"discount_price\", \"reordered\", \"add_to_cart_order\"]]]\n",
        "  r_predictions = cbfmodel.predict(X_all).flatten()\n",
        "\n",
        "  # Create a list of tuples containing product ID along with its predicted rating\n",
        "  product_ratings = list(zip(all_products['product_id'], r_predictions))\n",
        "\n",
        "  # Sort the product_ratings list by its predicted rating in descending order\n",
        "  product_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "  # Get top 10 recommendations without duplicates (product id recommended only 1 time)\n",
        "  recommended_products = []\n",
        "  recommended_product_ids = set()\n",
        "\n",
        "  for product_id, _ in product_ratings:\n",
        "      if product_id not in recommended_product_ids:\n",
        "          recommended_products.append((product_id, _))\n",
        "          recommended_product_ids.add(product_id)\n",
        "      if len(recommended_products) >= 10:\n",
        "          break\n",
        "\n",
        "  # Filter the original dataset based on the recommended product IDs\n",
        "  top_10_recommendations = all_products[all_products['product_id'].isin([p[0] for p in recommended_products])]\n",
        "\n",
        "  # Remove duplicate product IDs from the recommendations\n",
        "  top_10_recommendations = top_10_recommendations.drop_duplicates(subset='product_id')\n",
        "\n",
        "  # Keep the top 10 recommendations (if there are more than 10 after removing duplicates)\n",
        "  top_10_recommendations = top_10_recommendations.head(10)\n",
        "\n",
        "  # process the top 10 recommendations dataframe to get the required dataframe\n",
        "  pred_rating = pd.DataFrame(product_ratings) # make the product_ratings list into dataframe\n",
        "  pred_rating.columns =['product_id','cbf_ratings'] # give name to the columns of the dataframe\n",
        "  pred_rating = pred_rating.drop_duplicates(subset='product_id', keep='first') # drop rows with duplicate product id\n",
        "  cbfrecs = top_10_recommendations[['product_id', 'name','discount_price','category']] # choose the relevant columns to be displayed (product id and its info)\n",
        "  # merge the product info dataframe with the predicted ratings to get dataframes with product id , info and its predictedratings\n",
        "  cbfinfo = pd.merge(cbfrecs, pred_rating, on='product_id')\n",
        "  cbfinfo = cbfinfo.drop_duplicates(subset='product_id', keep='first') # drop rows with duplicate product id\n",
        "  # reverse transform the rescaled price\n",
        "  cbfinfo['discount_price'] = cbfinfo['discount_price'] * (df['discount_price'].max()- df['discount_price'].min() ) + df['discount_price'].min() \n",
        "\n",
        "  return cbfinfo , pred_rating\n",
        "\n",
        "\n",
        "# function to combine the results from 2 models\n",
        "def finaldataset(df,dataset,user_id,cbfmodel,clfmodel):\n",
        "  # get final collaborative filtering top 10 result data\n",
        "  clfinfo = collaborative_filtering_model(df,dataset, user_id,clfmodel)\n",
        "  cbfinfo , pred_rating = content_based_model(df, dataset, user_id, cbfmodel)\n",
        "  finalclf =  pd.merge(clfinfo, pred_rating, on='product_id', how='left')\n",
        "\n",
        "  # get final content-based filtering top 10 result data\n",
        "  product_ids = [x for x in cbfinfo['product_id']] \n",
        "  user_mapping = {user_id: i for i, user_id in enumerate(dataset['user_id'].unique())}\n",
        "  product_mapping = {item_id: i for i, item_id in enumerate(dataset['product_id'].unique())}\n",
        "  user_ids = np.full(len(product_ids), user_mapping[user_id])\n",
        "  item_ids = np.array([product_mapping[product_id] for product_id in product_ids])\n",
        "  predictions = clfmodel.predict([user_ids, item_ids]).flatten()\n",
        "  clf_predictions = pd.DataFrame({'product_id': product_ids,'clf_ratings': predictions})\n",
        "  finalcbf =  pd.merge(cbfinfo, clf_predictions, on='product_id', how='left')\n",
        "  \n",
        "  # combine the result\n",
        "  combined = pd.concat([finalclf, finalcbf], axis=0)\n",
        "  combined['cbf_ratings'] = combined['cbf_ratings'] * (df['ratings'].max() - df['ratings'].min() ) + df['ratings'].min()\n",
        "  combined['cbf_ratings'] = combined['cbf_ratings'].clip(lower=0.0, upper=5.0)\n",
        "  combined['clf_ratings'] = combined['clf_ratings'] * (df['ratings'].max() - df['ratings'].min() ) + df['ratings'].min()\n",
        "  combined['clf_ratings'] = combined['clf_ratings'].clip(lower=0.0, upper=5.0)\n",
        "  combined = combined.drop_duplicates(subset='product_id', keep='first')\n",
        "\n",
        "  return combined\n",
        "\n",
        "# choose the top 10 recommendations from hybrid models (combination of 2 models) \n",
        "def hybrid_recommend(df,dataset,user_id,cbfmodel,clfmodel,budget):\n",
        "    # get the combined dataset\n",
        "    all_recs = finaldataset(df,dataset,user_id,cbfmodel,clfmodel)\n",
        "\n",
        "    # Calculate the average predicted rating for both recommendations\n",
        "    clf_avg_rating = np.mean(all_recs['clf_ratings'])\n",
        "    cbf_avg_rating = np.mean(all_recs['cbf_ratings'])\n",
        "\n",
        "    # Get the final recommendations based on weighted average ratings of each product from the 2 models\n",
        "    all_recs['weighted_avg'] = (all_recs['clf_ratings'] * clf_avg_rating + all_recs['cbf_ratings']* cbf_avg_rating) / 2\n",
        "    hybrid_recommendations = all_recs[['product_id','weighted_avg','discount_price']].values.tolist()\n",
        "\n",
        "    # Sort the recommendations by the weighted average ratings in descending order\n",
        "    hybrid_recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Filter the recommendations based on the user's budget\n",
        "    filtered_recommendations = []\n",
        "    total_cost = 0\n",
        "    for product, rating,price in hybrid_recommendations:\n",
        "        product_cost = price\n",
        "        if total_cost + product_cost <= budget:\n",
        "            filtered_recommendations.append(product)\n",
        "            total_cost += product_cost\n",
        "        if len(filtered_recommendations) >= 10: # limit recommendations to 10 items max\n",
        "            break\n",
        "\n",
        "    return filtered_recommendations, total_cost # return the recommendations and total cost of the recommended items\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JSON"
      ],
      "metadata": {
        "id": "k7Zims6-Y8lx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Add an API endpoint for recommendations\n",
        "@app.route('/recommendations', methods=['POST'])\n",
        "def get_recommendations():\n",
        "    # Load the transaction dataset\n",
        "    df = pd.read_csv('/content/drive/MyDrive/final_dataset.csv')\n",
        "    df = df.drop([\"Unnamed: 0\"], axis=1)\n",
        "\n",
        "    # Load the collaborative filtering and content based recommender system model\n",
        "    loaded_cbf_model = load_model('/content/drive/MyDrive/cbf_model.h5')\n",
        "    loaded_clf_model = load_model('/content/drive/MyDrive/clf_model.h5')\n",
        "\n",
        "    # Preprocess the dataset (rescale the data and label encoding categorical data)\n",
        "    dataset = df.copy()\n",
        "    scaler = MinMaxScaler()\n",
        "    dataset[[\"actual_price\", \"discount_price\", \"ratings\", \"add_to_cart_order\"]] = scaler.fit_transform(dataset[[\"actual_price\", \"discount_price\", \"ratings\", \"add_to_cart_order\"]])\n",
        "    dataset['category_id'] = LabelEncoder().fit_transform(dataset['category'])\n",
        "\n",
        "    # request data / input from user\n",
        "    user_id = request.json['user_id'] # request user id\n",
        "    budget = request.json['budget'] # request budget \n",
        "\n",
        "    # Get the hybrid recommendations using collaborative filtering and content-based models\n",
        "    recommendations = hybrid_recommend(df, dataset, user_id, loaded_cbf_model, loaded_clf_model, budget)\n",
        "\n",
        "    # Return the recommendations as a JSON response\n",
        "    return jsonify(recommendations)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGIZZdaxqaV_",
        "outputId": "99973f3e-77b2-4118-d631-3ee47468c6aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "oH1Gp1nPROfb"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}